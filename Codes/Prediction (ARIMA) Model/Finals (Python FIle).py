# -*- coding: utf-8 -*-
"""Finals.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yRxjOjGKU95p8xNmPQLMoIbkl4G4lYbu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt



"""Inserting Our pre processed dataset."""

df = pd.read_csv('output.csv')

df.head()

"""As we can see, there are 7 columns inlcuding 'Unnamed : 0'. which is unnecessary. Lets drop this column."""

df.drop(['Unnamed: 0'], axis =1, inplace = True)

df.head()

"""Now it looks good. we have all necessarry data."""

df.describe()

"""The data describe shows there are 2612 rows.and there range is not same,there mean,std is cartaile value, all are higly varience."""

df.info()

"""Except the 'Created_at' columns , all data types are float. That we want"""



import seaborn as sns

"""Let's see the correlation"""

cor = df.corr()
sns.heatmap(cor, annot = True)
plt.show()

"""As we can see they are not highyly correlated with each other. Let's see the pairplot."""

sns.pairplot(df)

"""Let's plot time series data individully. Firsly week with humidity
There are 2612 rows, which is a lot of data with 3+ minutes intervel .which doesn't make sence.We want to predict all the parameters in one hour intervel. lets recreate hour daaset.
"""

df.set_index(['created_at'],inplace =True, drop = True)
df.index = pd.to_datetime(df.index)
jf = df.resample('H', label='right', closed='right').mean()
jf.dropna(inplace = True)
jf.head()



"""All done. We have succefully rebuiild the dataset with one hour intervel."""

jf.info()

"""Now we have all 7 days data with one hour intervel. so our target is now, train first six days data and forecast the final day data."""

# Create Training and Test
def split_data(data):
  train = data[:144]
  test = data[144:]
  return train, test

train_humidity, test_humidity = split_data(jf.humidity)
train_pm,test_pm = split_data(jf.pm)
train_co,test_co = split_data(jf.co)
train_temp,test_temp = split_data(jf.Temp)
train_nh3,test_nh3 = split_data(jf.nh3) 
len(test_co)

"""Now we have to test all the parameters to check wheather it's stationay or not using ADF test"""

from statsmodels.tsa.stattools import adfuller
def test_for_stationary(input_data):
    r_mean = input_data.rolling(window = 7,center=False).mean()
    r_std = input_data.rolling(window = 7,center=False).std()
    
    # plotting the data
    given = plt.plot(input_data, color = 'blue', label = 'given_series')
    rolling_mean = plt.plot(r_mean, color = 'red', label = 'rolling_mean')
    rolling_std = plt.plot(r_std, color ='green', label = 'rolling_std')
    plt.legend(loc = 'best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)
    
     #Perform Dickey-Fuller test:
    print('Results of Dickey-Fuller Test:')
    dftest = adfuller(input_data)
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print(dfoutput)

test_for_stationary(train_humidity)

"""According to dicky fuller test, Test stat is less than critical value. and p-values also significantly smaller than 0.05.Now let's test pm"""

test_for_stationary(train_pm)

"""Looks good.lets look over co."""

test_for_stationary(train_co)

"""This is also looks good. lets look over Nh3"""

test_for_stationary(train_nh3)

"""Here is it.Nh3, which is not statinary at all.the p value is greater than the threshold,test stat is also greater than the critical value.
we have to make it non stationary using log transformed or other method.before make it stationary , lets test tempereture.
"""



test_for_stationary(train_temp)

"""it looks good. But Critical value is almost equal to test stat. which is not good. but okay for. Later on we will tune the parameter. Then , if need , we will change.For now lets apply log transform technique on nh3"""

def log_transformed(data):

  ts_logtransformed = np.log(data)
  plt.plot(ts_logtransformed)
  return ts_logtransformed

ts_logtransformed_nh3 = log_transformed(train_nh3)

"""Smooth it by rolling average"""

def rolling_avg(data):

  Rolling_average = data.rolling(window = 7, center= False).mean()
  plt.plot(data, label = 'Log Transformed')
  plt.plot(Rolling_average, color = 'red', label = 'Rolling Average')
  plt.legend(loc = 'best')
  return Rolling_average

Rolling_average_nh3 = rolling_avg(train_nh3)

def log_rol_def(data1,data2):


  log_Rolling_difference = data1 - data2
  log_Rolling_difference.dropna(inplace=True)
  plt.plot(log_Rolling_difference)
  return log_Rolling_difference

log_Rolling_diff_nh3 = log_rol_def(ts_logtransformed_nh3,Rolling_average_nh3)

test_for_stationary(log_Rolling_diff_nh3)

"""It looks over differencing.the P value is greater than 0.05, and the critical value(1%) is also less than our test statistics. theoritically , now it is not stationary. lets apply log transformed method."""



"""Now it looks cool.The critical value(1%) is greater than our test stat. which means , we are 99% sure that, our dataset is statioanry.P value is also very less than threshold.So we got out d term for Humidity which is 1.
Now it's time to check our P and q term using acf and pcf plot.
"""

def diff_logtrans(data, n):


  ts_diff_logtrans = data - data.shift(n)
  plt.plot(ts_diff_logtrans)
  return ts_diff_logtrans

ts_diff_logtrans_nh3 = diff_logtrans(ts_logtransformed_nh3,10)

ts_diff_logtrans_nh3.dropna(inplace=True)
test_for_stationary(ts_diff_logtrans_nh3)

"""A little change , but not up to the mar. lets apply differnecing."""

t_train_nh3 = train_nh3.diff()
#t_train_humidity = t_train_humidity.dropna(inplace=True)
test_for_stationary(t_train_nh3[1:])

"""Now it looks stationary. As we can see the test stat is lower than the critical value(1%) and also the p value is also less than 0.05(threshold)"""

from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
from matplotlib import pyplot

def acf_pcf(data):

  pyplot.figure()
  pyplot.subplot(211)
  plot_acf(data, ax=pyplot.gca(),lags=40)
  pyplot.subplot(212)
  plot_pacf(data, ax=pyplot.gca(), lags=50)
  pyplot.show()

acf_pcf(train_nh3)
acf_pcf(train_humidity)
acf_pcf(train_pm)
acf_pcf(train_co)
acf_pcf(train_temp)

from pandas.plotting import autocorrelation_plot as acf

acf(train_nh3, label="Nh3")
acf(train_humidity, label = 'Humidity')
acf(train_pm, label = "PM")
acf(train_co, label = "CO")
acf(train_temp, label = "Temp")



"""This is the ACF and PACF plot of all the parameters. As we can see , in case Temperature , there is bit of seasonality. for this we can set the d=1 and tune other parameters (p,q). the lower the AIC,BIC the better the model.ACF,PACF just an assumption of p,Q. We need to tune the model and check which combination , gives us better accuracy.In case of that, we assumed , for CO, p,d,q =  1, 0, 2(ARMA), PM p,d,q=3,0,1 (ARMA) temp 5,1,1(ARIMA) humidity 1,1,1(ARIMA),nh3 p,d,q= 2,1,3(ARIMA)"""

from statsmodels.tsa.arima_model import ARIMA

def arima (p,d,q,train):


  model = ARIMA(train, order=(p, d, q))  
  results_ARIMA = model.fit(trend= 'nc', disp=-1)  
  plt.plot(results_ARIMA.fittedvalues, color='red', label = 'p = '+str(p)+','+'q = '+str(q))
  RSS =results_ARIMA.fittedvalues-train
  RSS.dropna(inplace=True)
  plt.title('RSS: %.4f'% sum(RSS**2))
  plt.legend(loc='best')
  return results_ARIMA,RSS

model_fit_nh3,rss_nh3=arima(2,1,3,train_nh3)
model_fit_nh3.plot_predict(dynamic= False)
print(model_fit_nh3.summary())

model_fit_humidity,rss_humidity=arima(1,1,1,train_humidity)
model_fit_humidity.plot_predict(dynamic= False)
print(model_fit_humidity.summary())



model_fit_co,rss_co = arima(1,0,2,train_co)

model_fit_co.plot_predict(dynamic= False)
print(model_fit_co.summary())

model_fit_pm,rss_pm = arima(3,0,1,train_pm)
model_fit_pm.plot_predict(dynamic= False)
print(model_fit_pm.summary())

model_fit_temp,rss_temp= arima(5,1,1,train_temp)
model_fit_temp.plot_predict(dynamic= False)
print(model_fit_temp.summary())

def forecast(fitted,n,train,test,par):
    
    # Forecast
    fc, se, conf = fitted.forecast(n, alpha=0.05)  # 95% conf
    
    # Make as pandas series
    fc_series = pd.Series(fc, index=test_pm.index)
    lower_series = pd.Series(conf[:, 0], index=test.index)
    upper_series = pd.Series(conf[:, 1], index=test.index)
    
    
    # Plot
    plt.figure(figsize=(12,5), dpi=100)
    plt.plot(train, label='training')
    plt.plot(test, label='actual')
    plt.plot(fc_series, label='forecast')
    plt.fill_between(lower_series.index, lower_series, upper_series, 
                     color='k', alpha=.15)
    plt.title('Forecast vs Actuals '+"("+par+")")
    plt.legend(loc='upper left', fontsize=8)
    plt.show()
    
    return fc_series

predicted_humidity = forecast(model_fit_humidity,24,train_humidity,test_humidity,"Humidity")

predicted_nh3 = forecast(model_fit_nh3,24,train_nh3,test_nh3, "Ammonia")

predicted_pm = forecast(model_fit_pm,24,train_pm,test_pm,"PM")

predicted_co = forecast(model_fit_co,24,train_co,test_co,"CO")

predicted_temp = forecast(model_fit_temp,24,train_temp,test_temp,"Temperature")

def mean_absolute_percentage_error(y_true, y_pred): 
    


    return np.mean(np.abs(y_pred - y_true)/np.abs(y_true))*100

mape_humidity = mean_absolute_percentage_error(test_humidity,predicted_humidity)
print("Mape of humidity "+str(mape_humidity))

mape_nh3 = mean_absolute_percentage_error(test_nh3,predicted_nh3)
print("Mape of nh3 "+str(mape_nh3))

mape_co = mean_absolute_percentage_error(test_co,predicted_co)
print("Mape of CO "+str(mape_co))

mape_temp = mean_absolute_percentage_error(test_temp,predicted_temp)
print("Mape of Temperature "+str(mape_temp))

mape_pm = mean_absolute_percentage_error(test_pm,predicted_pm)
print("Mape of PM "+str(mape_pm))


"""p=2, q=8"""



